{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7344c13a-bb16-41e0-89a8-66b9438ad412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PARCtorch.PARCv2 import PARCv2\n",
    "from PARCtorch.differentiator.differentiator import Differentiator\n",
    "from PARCtorch.differentiator.finitedifference import FiniteDifference\n",
    "from PARCtorch.integrator.integrator import Integrator\n",
    "from PARCtorch.integrator.heun import Heun\n",
    "from PARCtorch.utilities.unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510f668a-092f-4454-b8d2-c55f8ffed09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from glob import glob\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443377ca-2039-47f2-8ce9-e40a21446ac8",
   "metadata": {},
   "source": [
    "### Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eacb52a-51a6-484b-bfbb-6a4a6e6e1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burgers: u, v\n",
    "# Adv: all vars\n",
    "# Dif: all vars\n",
    "n_fe_features = 64\n",
    "unet_burgers = UNet(\n",
    "    [64, 64 * 2, 64 * 4],\n",
    "    3,\n",
    "    n_fe_features,\n",
    "    up_block_use_concat=[False, True],\n",
    "    skip_connection_indices=[0],\n",
    ").cuda()\n",
    "right_diff = FiniteDifference(padding_mode=\"replicate\").cuda()\n",
    "heun_int = Heun().cuda()\n",
    "diff_burgers = Differentiator(\n",
    "    1,  # 1 state variables: mu. We always assume 2 velocity being the last 2 channels\n",
    "    n_fe_features,  # Number of features returned by the feature extraction network: 64\n",
    "    [1, 2],  # Channel indices to calculate advection: u and v\n",
    "    [1, 2],  # Channel indices to calculate diffusion: u and v\n",
    "    unet_burgers,  # Feature extraction network: unet_burgers\n",
    "    \"constant\",  # Padding mode: constant padding of zero\n",
    "    right_diff,  # Finite difference method: replication of image_gradients\n",
    ").cuda()\n",
    "burgers_int = Integrator(\n",
    "    True, [], heun_int, [None, None, None], \"constant\", right_diff\n",
    ")\n",
    "criterion = torch.nn.L1Loss().cuda()\n",
    "model = PARCv2(diff_burgers, burgers_int, criterion).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e1f82-4c7c-4a6f-a7ef-17f0f011c57a",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638aae92-b156-4fb6-acbf-fe3649014d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "npy_patterns = \"/home/xc7ts/experiments/burgers_2d/train_data/*.npy\"\n",
    "future_steps = 1\n",
    "max_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91431e5c-799c-4038-971b-602f68caf175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurgersSimulation(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        npy_path,\n",
    "        future_steps=1,\n",
    "        max_len=None,\n",
    "        timestep=None,\n",
    "        min_val=torch.tensor([0.0, 0.0, 0.0], dtype=torch.float32),\n",
    "        max_val=torch.tensor([15000.0, 1.0, 1.0], dtype=torch.float32),\n",
    "        epsilon=1e-9,\n",
    "    ):\n",
    "        self.npy_path = npy_path\n",
    "        self.future_steps = future_steps\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "        if max_len is not None:\n",
    "            self.max_len = max_len\n",
    "        else:\n",
    "            tmp = np.load(npy_path, mmap_mode=\"r\")\n",
    "            self.max_len = tmp.shape[2] - self.future_steps\n",
    "        if timestep is not None:\n",
    "            self.timestep = timestep\n",
    "        else:\n",
    "            self.timestep = 1.0 / self.max_len\n",
    "        self.re = self.extract_Re_number(npy_path)\n",
    "        self.t0 = 0.0\n",
    "        self.t1 = (\n",
    "            torch.tensor(range(1, self.future_steps + 1), dtype=torch.float32)\n",
    "            * self.timestep\n",
    "        )\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def extract_Re_number(self, filename):\n",
    "        base_name = os.path.basename(\n",
    "            filename\n",
    "        )  # e.g., 'burgers_train_7500_9_8.npy'\n",
    "        try:\n",
    "            parts = base_name.split(\"_\")\n",
    "            Re_str = parts[2]  # '7500' in 'burgers_train_7500_9_8.npy'\n",
    "            Re_number = float(Re_str)\n",
    "        except (IndexError, ValueError) as e:\n",
    "            raise ValueError(\n",
    "                f\"Filename '{filename}' is not in the expected format 'burgers_train_<Re>_*.npy'.\"\n",
    "            ) from e\n",
    "        return Re_number\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        tmp = np.load(self.npy_path, mmap_mode=\"r\")\n",
    "        all_snaps = torch.tensor(\n",
    "            tmp[:, :, i : i + self.future_steps + 1, :], dtype=torch.float32\n",
    "        ).permute(2, 3, 0, 1)\n",
    "        all_re = (\n",
    "            torch.ones(\n",
    "                all_snaps.shape[0],\n",
    "                1,\n",
    "                all_snaps.shape[2],\n",
    "                all_snaps.shape[3],\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "            * self.re\n",
    "        )\n",
    "        sim = torch.cat([all_re, all_snaps], 1)\n",
    "        # Normalization\n",
    "        sim = (sim - self.min_val[None, :, None, None]) / (\n",
    "            self.max_val[None, :, None, None]\n",
    "            - self.min_val[None, :, None, None]\n",
    "            + self.epsilon\n",
    "        )\n",
    "        return sim[0], self.t0, self.t1, sim[1:]\n",
    "\n",
    "\n",
    "def simulation_collate_fn(batch):\n",
    "    ic, t0, t1, target = zip(*batch)\n",
    "    # Stack the initial conditions into a tensor\n",
    "    ic = torch.stack(ic, dim=0)  # (batch_size, 3, 64, 64)\n",
    "    # Since t0 is always 0.0, return a single scalar tensor\n",
    "    t0 = torch.tensor(0.0, dtype=torch.float32)  # Scalar tensor\n",
    "    # Since t1 is consistent across all samples, take the first one\n",
    "    t1 = t1[0]  # (future_steps,)\n",
    "    # Stack targets into a tensor and permute to match desired shape\n",
    "    target = torch.stack(target, dim=0).permute(\n",
    "        1, 0, 2, 3, 4\n",
    "    )  # (future_steps, batch_size, 3, 64, 64)\n",
    "    return ic, t0, t1, target\n",
    "\n",
    "\n",
    "list_burgers_train_dataset = []\n",
    "for each_npy in glob(npy_patterns):\n",
    "    list_burgers_train_dataset.append(BurgersSimulation(each_npy))\n",
    "burgers_train_dataset = ConcatDataset(list_burgers_train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    burgers_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=simulation_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a178c0-ada5-4c96-8852-5e06fb3ba65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e8b624-eae0-4f1e-9789-a81e78198c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic shape: torch.Size([8, 3, 64, 64])\n",
      "t0: tensor(0.)\n",
      "t1: tensor([0.0100])\n",
      "target shape: torch.Size([1, 8, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    ic, t0, t1, target = batch\n",
    "    print(\"ic shape:\", ic.shape)  # (batch_size, 3, 64, 64)\n",
    "    print(\"t0:\", t0)  # 0.0\n",
    "    print(\"t1:\", t1)  # (future_steps,)\n",
    "    print(\"target shape:\", target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961911c4-72f8-492f-8fcc-7e3b80b68ca0",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c1613f6-342b-451d-b54c-b0c877466ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d7a85e-1bad-4a91-99f4-2c5c989a8e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:46<00:00, 26.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.000815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:44<00:00, 28.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:44<00:00, 27.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.000096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:45<00:00, 27.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.000073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:44<00:00, 28.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:45<00:00, 27.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.000055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:44<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.000051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:44<00:00, 27.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.000046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:44<00:00, 27.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.000043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:45<00:00, 27.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.000040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    epoch_loss = 0.0\n",
    "    for each_train_data in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        ic, t0, t1, gt = each_train_data\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(ic.cuda(), t0.cuda(), t1.cuda())\n",
    "        loss = criterion(pred[:, :, 1:, :, :], gt.cuda()[:, :, 1:, :, :])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{max_epoch}], Loss: {epoch_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1701a9d-58a9-4da8-8ea6-d1ec86bb1afa",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13d204c2-1ece-4843-a87d-1b66c69b215b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PARCv2:\n\tMissing key(s) in state_dict: \"differentiator.list_adv.1.cdiff.dy_filter\", \"differentiator.list_adv.1.cdiff.dx_filter\", \"differentiator.list_dif.1.cdiff.dy_filter\", \"differentiator.list_dif.1.cdiff.dx_filter\", \"differentiator.list_mar.1.spade.spade1.initial_conv.0.weight\", \"differentiator.list_mar.1.spade.spade1.initial_conv.0.bias\", \"differentiator.list_mar.1.spade.spade1.gamma_conv.weight\", \"differentiator.list_mar.1.spade.spade1.gamma_conv.bias\", \"differentiator.list_mar.1.spade.spade1.beta_conv.weight\", \"differentiator.list_mar.1.spade.spade1.beta_conv.bias\", \"differentiator.list_mar.1.spade.conv1.weight\", \"differentiator.list_mar.1.spade.conv1.bias\", \"differentiator.list_mar.1.spade.spade2.initial_conv.0.weight\", \"differentiator.list_mar.1.spade.spade2.initial_conv.0.bias\", \"differentiator.list_mar.1.spade.spade2.gamma_conv.weight\", \"differentiator.list_mar.1.spade.spade2.gamma_conv.bias\", \"differentiator.list_mar.1.spade.spade2.beta_conv.weight\", \"differentiator.list_mar.1.spade.spade2.beta_conv.bias\", \"differentiator.list_mar.1.spade.conv2.weight\", \"differentiator.list_mar.1.spade.conv2.bias\", \"differentiator.list_mar.1.spade.spade_skip.initial_conv.0.weight\", \"differentiator.list_mar.1.spade.spade_skip.initial_conv.0.bias\", \"differentiator.list_mar.1.spade.spade_skip.gamma_conv.weight\", \"differentiator.list_mar.1.spade.spade_skip.gamma_conv.bias\", \"differentiator.list_mar.1.spade.spade_skip.beta_conv.weight\", \"differentiator.list_mar.1.spade.spade_skip.beta_conv.bias\", \"differentiator.list_mar.1.spade.conv_skip.weight\", \"differentiator.list_mar.1.spade.conv_skip.bias\", \"differentiator.list_mar.1.resnet.conv1.0.weight\", \"differentiator.list_mar.1.resnet.conv1.0.bias\", \"differentiator.list_mar.1.resnet.conv2.0.weight\", \"differentiator.list_mar.1.resnet.conv2.0.bias\", \"differentiator.list_mar.1.resnet.path.0.conv1.0.weight\", \"differentiator.list_mar.1.resnet.path.0.conv1.0.bias\", \"differentiator.list_mar.1.resnet.path.0.conv2.0.weight\", \"differentiator.list_mar.1.resnet.path.0.conv2.0.bias\", \"differentiator.list_mar.1.resnet.path.1.conv1.0.weight\", \"differentiator.list_mar.1.resnet.path.1.conv1.0.bias\", \"differentiator.list_mar.1.resnet.path.1.conv2.0.weight\", \"differentiator.list_mar.1.resnet.path.1.conv2.0.bias\", \"differentiator.list_mar.1.conv_out.weight\", \"differentiator.list_mar.1.conv_out.bias\". \n\tUnexpected key(s) in state_dict: \"differentiator.list_adv.3.cdiff.dy_filter\", \"differentiator.list_adv.3.cdiff.dx_filter\", \"differentiator.list_dif.3.cdiff.dy_filter\", \"differentiator.list_dif.3.cdiff.dx_filter\", \"differentiator.list_mar.2.spade.spade1.initial_conv.0.weight\", \"differentiator.list_mar.2.spade.spade1.initial_conv.0.bias\", \"differentiator.list_mar.2.spade.spade1.gamma_conv.weight\", \"differentiator.list_mar.2.spade.spade1.gamma_conv.bias\", \"differentiator.list_mar.2.spade.spade1.beta_conv.weight\", \"differentiator.list_mar.2.spade.spade1.beta_conv.bias\", \"differentiator.list_mar.2.spade.conv1.weight\", \"differentiator.list_mar.2.spade.conv1.bias\", \"differentiator.list_mar.2.spade.spade2.initial_conv.0.weight\", \"differentiator.list_mar.2.spade.spade2.initial_conv.0.bias\", \"differentiator.list_mar.2.spade.spade2.gamma_conv.weight\", \"differentiator.list_mar.2.spade.spade2.gamma_conv.bias\", \"differentiator.list_mar.2.spade.spade2.beta_conv.weight\", \"differentiator.list_mar.2.spade.spade2.beta_conv.bias\", \"differentiator.list_mar.2.spade.conv2.weight\", \"differentiator.list_mar.2.spade.conv2.bias\", \"differentiator.list_mar.2.spade.spade_skip.initial_conv.0.weight\", \"differentiator.list_mar.2.spade.spade_skip.initial_conv.0.bias\", \"differentiator.list_mar.2.spade.spade_skip.gamma_conv.weight\", \"differentiator.list_mar.2.spade.spade_skip.gamma_conv.bias\", \"differentiator.list_mar.2.spade.spade_skip.beta_conv.weight\", \"differentiator.list_mar.2.spade.spade_skip.beta_conv.bias\", \"differentiator.list_mar.2.spade.conv_skip.weight\", \"differentiator.list_mar.2.spade.conv_skip.bias\", \"differentiator.list_mar.2.resnet.conv1.0.weight\", \"differentiator.list_mar.2.resnet.conv1.0.bias\", \"differentiator.list_mar.2.resnet.conv2.0.weight\", \"differentiator.list_mar.2.resnet.conv2.0.bias\", \"differentiator.list_mar.2.resnet.path.0.conv1.0.weight\", \"differentiator.list_mar.2.resnet.path.0.conv1.0.bias\", \"differentiator.list_mar.2.resnet.path.0.conv2.0.weight\", \"differentiator.list_mar.2.resnet.path.0.conv2.0.bias\", \"differentiator.list_mar.2.resnet.path.1.conv1.0.weight\", \"differentiator.list_mar.2.resnet.path.1.conv1.0.bias\", \"differentiator.list_mar.2.resnet.path.1.conv2.0.weight\", \"differentiator.list_mar.2.resnet.path.1.conv2.0.bias\", \"differentiator.list_mar.2.conv_out.weight\", \"differentiator.list_mar.2.conv_out.bias\", \"differentiator.feature_extraction.downBlocks.2.doubleConv.0.weight\", \"differentiator.feature_extraction.downBlocks.2.doubleConv.0.bias\", \"differentiator.feature_extraction.downBlocks.2.doubleConv.2.weight\", \"differentiator.feature_extraction.downBlocks.2.doubleConv.2.bias\", \"differentiator.feature_extraction.downBlocks.3.doubleConv.0.weight\", \"differentiator.feature_extraction.downBlocks.3.doubleConv.0.bias\", \"differentiator.feature_extraction.downBlocks.3.doubleConv.2.weight\", \"differentiator.feature_extraction.downBlocks.3.doubleConv.2.bias\", \"differentiator.feature_extraction.upBlocks.2.doubleConv.0.weight\", \"differentiator.feature_extraction.upBlocks.2.doubleConv.0.bias\", \"differentiator.feature_extraction.upBlocks.2.doubleConv.2.weight\", \"differentiator.feature_extraction.upBlocks.2.doubleConv.2.bias\", \"differentiator.feature_extraction.upBlocks.3.doubleConv.0.weight\", \"differentiator.feature_extraction.upBlocks.3.doubleConv.0.bias\", \"differentiator.feature_extraction.upBlocks.3.doubleConv.2.weight\", \"differentiator.feature_extraction.upBlocks.3.doubleConv.2.bias\", \"integrator.list_poi.0.poisson.cdiff.dy_filter\", \"integrator.list_poi.0.poisson.cdiff.dx_filter\", \"integrator.list_poi.0.conv.0.weight\", \"integrator.list_poi.0.conv.0.bias\", \"integrator.list_poi.0.conv.2.weight\", \"integrator.list_poi.0.conv.2.bias\", \"integrator.list_poi.0.conv.4.conv1.0.weight\", \"integrator.list_poi.0.conv.4.conv1.0.bias\", \"integrator.list_poi.0.conv.4.conv2.0.weight\", \"integrator.list_poi.0.conv.4.conv2.0.bias\", \"integrator.list_poi.0.conv.4.path.0.conv1.0.weight\", \"integrator.list_poi.0.conv.4.path.0.conv1.0.bias\", \"integrator.list_poi.0.conv.4.path.0.conv2.0.weight\", \"integrator.list_poi.0.conv.4.path.0.conv2.0.bias\", \"integrator.list_poi.0.conv.4.path.1.conv1.0.weight\", \"integrator.list_poi.0.conv.4.path.1.conv1.0.bias\", \"integrator.list_poi.0.conv.4.path.1.conv2.0.weight\", \"integrator.list_poi.0.conv.4.path.1.conv2.0.bias\", \"integrator.list_poi.0.conv.5.weight\", \"integrator.list_poi.0.conv.5.bias\". \n\tsize mismatch for differentiator.feature_extraction.doubleConv.0.weight: copying a param with shape torch.Size([64, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3, 3]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.0.doubleConv.0.weight: copying a param with shape torch.Size([512, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.0.doubleConv.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.0.doubleConv.2.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.0.doubleConv.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.1.doubleConv.0.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 192, 3, 3]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.1.doubleConv.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.1.doubleConv.2.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.1.doubleConv.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for differentiator.feature_extraction.finalConv.0.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for differentiator.feature_extraction.finalConv.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for differentiator.feature_extraction.finalConv.2.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for differentiator.feature_extraction.finalConv.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m t1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m     10\u001b[0m t1 \u001b[38;5;241m=\u001b[39m t1\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparcv2_burger/checkpoints/epoch_000490.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     14\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparcv2_burger/test_animation\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_2.4.1/lib/python3.12/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PARCv2:\n\tMissing key(s) in state_dict: \"differentiator.list_adv.1.cdiff.dy_filter\", \"differentiator.list_adv.1.cdiff.dx_filter\", \"differentiator.list_dif.1.cdiff.dy_filter\", \"differentiator.list_dif.1.cdiff.dx_filter\", \"differentiator.list_mar.1.spade.spade1.initial_conv.0.weight\", \"differentiator.list_mar.1.spade.spade1.initial_conv.0.bias\", \"differentiator.list_mar.1.spade.spade1.gamma_conv.weight\", \"differentiator.list_mar.1.spade.spade1.gamma_conv.bias\", \"differentiator.list_mar.1.spade.spade1.beta_conv.weight\", \"differentiator.list_mar.1.spade.spade1.beta_conv.bias\", \"differentiator.list_mar.1.spade.conv1.weight\", \"differentiator.list_mar.1.spade.conv1.bias\", \"differentiator.list_mar.1.spade.spade2.initial_conv.0.weight\", \"differentiator.list_mar.1.spade.spade2.initial_conv.0.bias\", \"differentiator.list_mar.1.spade.spade2.gamma_conv.weight\", \"differentiator.list_mar.1.spade.spade2.gamma_conv.bias\", \"differentiator.list_mar.1.spade.spade2.beta_conv.weight\", \"differentiator.list_mar.1.spade.spade2.beta_conv.bias\", \"differentiator.list_mar.1.spade.conv2.weight\", \"differentiator.list_mar.1.spade.conv2.bias\", \"differentiator.list_mar.1.spade.spade_skip.initial_conv.0.weight\", \"differentiator.list_mar.1.spade.spade_skip.initial_conv.0.bias\", \"differentiator.list_mar.1.spade.spade_skip.gamma_conv.weight\", \"differentiator.list_mar.1.spade.spade_skip.gamma_conv.bias\", \"differentiator.list_mar.1.spade.spade_skip.beta_conv.weight\", \"differentiator.list_mar.1.spade.spade_skip.beta_conv.bias\", \"differentiator.list_mar.1.spade.conv_skip.weight\", \"differentiator.list_mar.1.spade.conv_skip.bias\", \"differentiator.list_mar.1.resnet.conv1.0.weight\", \"differentiator.list_mar.1.resnet.conv1.0.bias\", \"differentiator.list_mar.1.resnet.conv2.0.weight\", \"differentiator.list_mar.1.resnet.conv2.0.bias\", \"differentiator.list_mar.1.resnet.path.0.conv1.0.weight\", \"differentiator.list_mar.1.resnet.path.0.conv1.0.bias\", \"differentiator.list_mar.1.resnet.path.0.conv2.0.weight\", \"differentiator.list_mar.1.resnet.path.0.conv2.0.bias\", \"differentiator.list_mar.1.resnet.path.1.conv1.0.weight\", \"differentiator.list_mar.1.resnet.path.1.conv1.0.bias\", \"differentiator.list_mar.1.resnet.path.1.conv2.0.weight\", \"differentiator.list_mar.1.resnet.path.1.conv2.0.bias\", \"differentiator.list_mar.1.conv_out.weight\", \"differentiator.list_mar.1.conv_out.bias\". \n\tUnexpected key(s) in state_dict: \"differentiator.list_adv.3.cdiff.dy_filter\", \"differentiator.list_adv.3.cdiff.dx_filter\", \"differentiator.list_dif.3.cdiff.dy_filter\", \"differentiator.list_dif.3.cdiff.dx_filter\", \"differentiator.list_mar.2.spade.spade1.initial_conv.0.weight\", \"differentiator.list_mar.2.spade.spade1.initial_conv.0.bias\", \"differentiator.list_mar.2.spade.spade1.gamma_conv.weight\", \"differentiator.list_mar.2.spade.spade1.gamma_conv.bias\", \"differentiator.list_mar.2.spade.spade1.beta_conv.weight\", \"differentiator.list_mar.2.spade.spade1.beta_conv.bias\", \"differentiator.list_mar.2.spade.conv1.weight\", \"differentiator.list_mar.2.spade.conv1.bias\", \"differentiator.list_mar.2.spade.spade2.initial_conv.0.weight\", \"differentiator.list_mar.2.spade.spade2.initial_conv.0.bias\", \"differentiator.list_mar.2.spade.spade2.gamma_conv.weight\", \"differentiator.list_mar.2.spade.spade2.gamma_conv.bias\", \"differentiator.list_mar.2.spade.spade2.beta_conv.weight\", \"differentiator.list_mar.2.spade.spade2.beta_conv.bias\", \"differentiator.list_mar.2.spade.conv2.weight\", \"differentiator.list_mar.2.spade.conv2.bias\", \"differentiator.list_mar.2.spade.spade_skip.initial_conv.0.weight\", \"differentiator.list_mar.2.spade.spade_skip.initial_conv.0.bias\", \"differentiator.list_mar.2.spade.spade_skip.gamma_conv.weight\", \"differentiator.list_mar.2.spade.spade_skip.gamma_conv.bias\", \"differentiator.list_mar.2.spade.spade_skip.beta_conv.weight\", \"differentiator.list_mar.2.spade.spade_skip.beta_conv.bias\", \"differentiator.list_mar.2.spade.conv_skip.weight\", \"differentiator.list_mar.2.spade.conv_skip.bias\", \"differentiator.list_mar.2.resnet.conv1.0.weight\", \"differentiator.list_mar.2.resnet.conv1.0.bias\", \"differentiator.list_mar.2.resnet.conv2.0.weight\", \"differentiator.list_mar.2.resnet.conv2.0.bias\", \"differentiator.list_mar.2.resnet.path.0.conv1.0.weight\", \"differentiator.list_mar.2.resnet.path.0.conv1.0.bias\", \"differentiator.list_mar.2.resnet.path.0.conv2.0.weight\", \"differentiator.list_mar.2.resnet.path.0.conv2.0.bias\", \"differentiator.list_mar.2.resnet.path.1.conv1.0.weight\", \"differentiator.list_mar.2.resnet.path.1.conv1.0.bias\", \"differentiator.list_mar.2.resnet.path.1.conv2.0.weight\", \"differentiator.list_mar.2.resnet.path.1.conv2.0.bias\", \"differentiator.list_mar.2.conv_out.weight\", \"differentiator.list_mar.2.conv_out.bias\", \"differentiator.feature_extraction.downBlocks.2.doubleConv.0.weight\", \"differentiator.feature_extraction.downBlocks.2.doubleConv.0.bias\", \"differentiator.feature_extraction.downBlocks.2.doubleConv.2.weight\", \"differentiator.feature_extraction.downBlocks.2.doubleConv.2.bias\", \"differentiator.feature_extraction.downBlocks.3.doubleConv.0.weight\", \"differentiator.feature_extraction.downBlocks.3.doubleConv.0.bias\", \"differentiator.feature_extraction.downBlocks.3.doubleConv.2.weight\", \"differentiator.feature_extraction.downBlocks.3.doubleConv.2.bias\", \"differentiator.feature_extraction.upBlocks.2.doubleConv.0.weight\", \"differentiator.feature_extraction.upBlocks.2.doubleConv.0.bias\", \"differentiator.feature_extraction.upBlocks.2.doubleConv.2.weight\", \"differentiator.feature_extraction.upBlocks.2.doubleConv.2.bias\", \"differentiator.feature_extraction.upBlocks.3.doubleConv.0.weight\", \"differentiator.feature_extraction.upBlocks.3.doubleConv.0.bias\", \"differentiator.feature_extraction.upBlocks.3.doubleConv.2.weight\", \"differentiator.feature_extraction.upBlocks.3.doubleConv.2.bias\", \"integrator.list_poi.0.poisson.cdiff.dy_filter\", \"integrator.list_poi.0.poisson.cdiff.dx_filter\", \"integrator.list_poi.0.conv.0.weight\", \"integrator.list_poi.0.conv.0.bias\", \"integrator.list_poi.0.conv.2.weight\", \"integrator.list_poi.0.conv.2.bias\", \"integrator.list_poi.0.conv.4.conv1.0.weight\", \"integrator.list_poi.0.conv.4.conv1.0.bias\", \"integrator.list_poi.0.conv.4.conv2.0.weight\", \"integrator.list_poi.0.conv.4.conv2.0.bias\", \"integrator.list_poi.0.conv.4.path.0.conv1.0.weight\", \"integrator.list_poi.0.conv.4.path.0.conv1.0.bias\", \"integrator.list_poi.0.conv.4.path.0.conv2.0.weight\", \"integrator.list_poi.0.conv.4.path.0.conv2.0.bias\", \"integrator.list_poi.0.conv.4.path.1.conv1.0.weight\", \"integrator.list_poi.0.conv.4.path.1.conv1.0.bias\", \"integrator.list_poi.0.conv.4.path.1.conv2.0.weight\", \"integrator.list_poi.0.conv.4.path.1.conv2.0.bias\", \"integrator.list_poi.0.conv.5.weight\", \"integrator.list_poi.0.conv.5.bias\". \n\tsize mismatch for differentiator.feature_extraction.doubleConv.0.weight: copying a param with shape torch.Size([64, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3, 3]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.0.doubleConv.0.weight: copying a param with shape torch.Size([512, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.0.doubleConv.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.0.doubleConv.2.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.0.doubleConv.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.1.doubleConv.0.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 192, 3, 3]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.1.doubleConv.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.1.doubleConv.2.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for differentiator.feature_extraction.upBlocks.1.doubleConv.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for differentiator.feature_extraction.finalConv.0.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for differentiator.feature_extraction.finalConv.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for differentiator.feature_extraction.finalConv.2.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for differentiator.feature_extraction.finalConv.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64])."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "vmin = torch.tensor([0.0, 0.0, 0.0], dtype=torch.float32)\n",
    "vmax = torch.tensor([15000.0, 1.0, 1.0], dtype=torch.float32)\n",
    "\n",
    "t0 = torch.tensor(0.0, dtype=torch.float32).cuda()\n",
    "t1 = torch.tensor(range(1, 101), dtype=torch.float32) * 0.01\n",
    "t1 = t1.cuda()\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\"parcv2_burger/checkpoints/epoch_000490.pt\", weights_only=True)\n",
    ")\n",
    "model.eval()\n",
    "os.makedirs(\"parcv2_burger/test_animation\", exist_ok=True)\n",
    "for each in glob(\"/home/xc7ts/experiments/burgers_2d/test_data/*.npy\"):\n",
    "    # Re\n",
    "    base_name = os.path.basename(each)\n",
    "    parts = base_name.split(\"_\")\n",
    "    re = float(parts[2])\n",
    "    # Initial condition\n",
    "    test_case = (\n",
    "        torch.tensor(np.load(each), dtype=torch.float32)\n",
    "        .permute(2, 3, 0, 1)\n",
    "        .unsqueeze(1)\n",
    "    )\n",
    "    test_re = (\n",
    "        torch.ones(\n",
    "            test_case.shape[0],\n",
    "            test_case.shape[1],\n",
    "            1,\n",
    "            test_case.shape[3],\n",
    "            test_case.shape[4],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        * re\n",
    "    )\n",
    "    test_gt = torch.cat([test_re, test_case], 2)\n",
    "    test_gt = (test_gt - vmin[None, None, :, None, None]) / (\n",
    "        vmax[None, :, None, None] - vmin[None, :, None, None] + 1e-9\n",
    "    )\n",
    "    test_ic = test_gt[0, :, :, :, :].cuda()\n",
    "    with torch.no_grad():\n",
    "        pred = model(test_ic, t0, t1)\n",
    "    vel_mag = torch.sqrt(\n",
    "        pred[:, 0, 1, :, :] * pred[:, 0, 1, :, :]\n",
    "        + pred[:, 0, 2, :, :] * pred[:, 0, 2, :, :]\n",
    "    )\n",
    "    vel_mag = vel_mag.detach().cpu().numpy()\n",
    "    # Animation\n",
    "    vel_mag_gt = (\n",
    "        torch.sqrt(\n",
    "            test_gt[1:, 0, 1, :, :] * test_gt[1:, 0, 1, :, :]\n",
    "            + test_gt[1:, 0, 2, :, :] * test_gt[1:, 0, 2, :, :]\n",
    "        )\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    p_max = np.max(vel_mag_gt)\n",
    "    im0 = ax0.imshow(vel_mag_gt[0, :, :], vmin=0.0, vmax=p_max)\n",
    "    ax0.set_title(\"GT\")\n",
    "    im1 = ax1.imshow(vel_mag[0, :, :], vmin=0.0, vmax=p_max)\n",
    "    ax1.set_title(\"PARCtorch\")\n",
    "\n",
    "    def animate(i):\n",
    "        im0.set_array(vel_mag_gt[i, :, :])\n",
    "        im1.set_array(vel_mag[i, :, :])\n",
    "        return im0, im1\n",
    "\n",
    "    anim_path = (\n",
    "        \"parcv2_burger/test_animation/\" + base_name.strip(\".npy\") + \".gif\"\n",
    "    )\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=100)\n",
    "    anim.save(anim_path, fps=5)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907d98e-25e1-4bd6-8375-ac8a41c67ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
